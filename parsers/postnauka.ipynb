{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Парсер Постнауки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from text_utils import BaseSource, BaseProcessor, BaseSink\n",
    "from text_utils import DefaultTextProcessor, DefaultDocumentProcessor, DefaultCollectionProcessor\n",
    "from text_utils import VowpalWabbitSink, MongoDbSink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим сначала пайплайн для одного документа (`PostnaukaFileSource`, `PostnaukaFileProcessor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pn_tags_trim = regex.compile(\"\\[(post|pcourse) [^\\]]+\\]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PostnaukaFileSource(BaseSource):\n",
    "    def fit(self, params, *args):\n",
    "        (text_path, meta_path) = params\n",
    "        self.text_path = text_path\n",
    "        self.meta_path = meta_path\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PostnaukaFileProcessor(BaseProcessor):\n",
    "    def __init__(self, stop_words):\n",
    "        self.doc_pipeline = Pipeline([\n",
    "            (\"text-processor\",     DefaultTextProcessor()),\n",
    "            (\"document-processor\", DefaultDocumentProcessor(stop_lemmas=stop_words)),\n",
    "        ])\n",
    "\n",
    "    def transform(self, src, *args):\n",
    "        # Parse text file\n",
    "        with src.text_path.open() as fi:\n",
    "            title = fi.readline().strip()\n",
    "            fi.readline()\n",
    "            description = fi.readline().strip()\n",
    "            fi.readline()\n",
    "            text = fi.read()\n",
    "            text = pn_tags_trim.sub(\"\", text)\n",
    "        # Parse meta file\n",
    "        flat_tags = []\n",
    "        authors = []\n",
    "        with src.meta_path.open() as fi:\n",
    "            for ln in fi:\n",
    "                toks = regex.split(\"\\s+\", ln, 2)\n",
    "                if toks[0] == \"post_tag\":\n",
    "                    flat_tags.append(toks[-1].strip().lower())\n",
    "                elif toks[0] == \"author\":\n",
    "                    authors.append(toks[-1].strip().lower())\n",
    "        # Run inner pipeline to form modalities\n",
    "        modalities = self.doc_pipeline.fit_transform(text)\n",
    "        # Finally, make a document and return it\n",
    "        doc = {}\n",
    "        doc[\"title\"] = title\n",
    "        doc[\"description\"] = description\n",
    "        doc[\"modalities\"] = modalities\n",
    "        doc[\"modalities\"][\"flat_tag\"] = flat_tags\n",
    "        doc[\"modalities\"][\"authors\"] = authors\n",
    "        doc[\"markdown\"] = text\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь определим пайплайн всей коллекции файлов на диске (`PostnaukaCollectionSource`, `PostnaukaCollectionProcessor`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PostnaukaCollectionSource(BaseSource):\n",
    "    def fit(self, root_path, *args):\n",
    "        stop_words = (root_path / \"stopwords.txt\").open().read().split()\n",
    "        self.root_path = root_path\n",
    "        # We will spawn this pipeline in parallel for each document\n",
    "        self.file_parser = Pipeline([\n",
    "            (\"take-file-name\",      PostnaukaFileSource()),\n",
    "            (\"convert-to-document\", PostnaukaFileProcessor(stop_words)),\n",
    "        ])\n",
    "        # Save source state\n",
    "        self.vw_file = (root_path / \"postnauka.txt\").open(\"w\")\n",
    "        self.files_paths = sorted(root_path.glob(\"raw_data/*.txt\"))\n",
    "        self.metas_paths = sorted(root_path.glob(\"raw_data/meta/*_meta.txt\"))\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class PostnaukaCollectionProcessor(BaseProcessor):\n",
    "    def transform(self, src, *args):\n",
    "        docs = []\n",
    "        f = FloatProgress(min=0, max=len(src.files_paths))\n",
    "        display(f)\n",
    "        for doc_id, (file_path, meta_path) in enumerate(zip(src.files_paths, src.metas_paths)):\n",
    "            # TODO: run these in parallel threads\n",
    "            doc = src.file_parser.fit_transform((file_path, meta_path))\n",
    "            doc[\"doc_id\"] = doc_id + 1\n",
    "            docs.append(doc)\n",
    "            f.value += 1\n",
    "        docs = DefaultCollectionProcessor(min_len=1, min_df=2).fit_transform(docs)\n",
    "        id_func = lambda doc: \"pn_%d\" % doc[\"doc_id\"]\n",
    "        # Save Markdown texts in MongoDB\n",
    "        MongoDbSink(\"postnauka\", id_func=id_func).fit_transform(docs)\n",
    "        # Save collection in Vowpal Wabbit format\n",
    "        VowpalWabbitSink(src.vw_file, id_func).fit_transform(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Построим парсер Постнауки из пайплайна, определенного выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postnauka_parser = Pipeline([\n",
    "    (\"take-root-path\",         PostnaukaCollectionSource()),\n",
    "    (\"process-the-collection\", PostnaukaCollectionProcessor()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запустим парсер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_path = Path(\"../datasets/postnauka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 41s, sys: 7.33 s, total: 2min 48s\n",
      "Wall time: 5min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "postnauka_parser.fit_transform(root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
