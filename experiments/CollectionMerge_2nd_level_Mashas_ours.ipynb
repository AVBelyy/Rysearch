{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Эксперимент по вливанию коллекции в тематическую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import urllib\n",
    "import pickle\n",
    "import pymongo\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import artm\n",
    "import hierarchy_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "db = pymongo.MongoClient()[\"datasets\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "prefix_to_col_map = {\"pn\": \"postnauka\", \"habr\": \"habrahabr\", \"elem\": \"elementy\"}\n",
    "\n",
    "def get_document(doc_id, with_markdown=False):\n",
    "    fields = {\"_id\": 1, \"title\": 1, \"modalities\": 1}\n",
    "    if with_markdown:\n",
    "        fields[\"markdown\"] = 1\n",
    "    prefix, _ = doc_id.split(\"_\", 1)\n",
    "    col_name = prefix_to_col_map[prefix]\n",
    "    return db[col_name].find_one({\"_id\": doc_id}, fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 33 ms, sys: 103 ms, total: 136 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Для регуляризатор иерархической когерентности необходимо прочитать матрицу C\n",
    "\n",
    "with open(\"../article/C_data.dump\", \"rb\") as fin:\n",
    "    C_data = pickle.load(fin)\n",
    "\n",
    "with open(\"../article/C_indices.dump\", \"rb\") as fin:\n",
    "    C_indices = pickle.load(fin)\n",
    "\n",
    "with open(\"../article/C_indptr.dump\", \"rb\") as fin:\n",
    "    C_indptr = pickle.load(fin)\n",
    "\n",
    "with open(\"../article/C_meta.dump\", \"rb\") as fin:\n",
    "    C_shape, C_dtype = pickle.load(fin)\n",
    "\n",
    "C = csr_matrix((C_data, C_indices, C_indptr), shape=C_shape, dtype=C_dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51 ms, sys: 2 ms, total: 53 ms\n",
      "Wall time: 57.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#  Костыль для определения модальности всех токенов словаря\n",
    "\n",
    "merged_mod_map = collections.defaultdict(list)\n",
    "\n",
    "with open(\"merged_vocab.txt\") as fin:\n",
    "    for token_id, row in enumerate(fin):\n",
    "        token, modality = row.strip().split()\n",
    "        merged_mod_map[modality].append(token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976\n",
      "27665\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Шаг 1 -- получение ранжированного списка документов для доливания\n",
    "\n",
    "reduced_dataset = False\n",
    "shuffled_dataset = False\n",
    "source_size = []\n",
    "\n",
    "docs_ids = list(map(lambda r: r[\"_id\"], db[\"postnauka\"].find({}, {\"_id\": 1})))\n",
    "\n",
    "D_a = len(docs_ids)\n",
    "print(D_a)\n",
    "source_size.append(D_a)\n",
    "\n",
    "for csv_name, thresh in ((\"classifier_output_habr.csv\", 0.5),\n",
    "                         (\"classifier_output_elem.csv\", 1.1)):\n",
    "    clf_output = pd.read_csv(csv_name)\n",
    "    clf_output.columns = [\"id\", \"proba\"]\n",
    "    clf_output = clf_output.set_index(\"id\")[\"proba\"]\n",
    "    clf_output = clf_output[clf_output >= thresh]\n",
    "\n",
    "    clf_output = clf_output.sort_values(ascending=False)\n",
    "\n",
    "    if reduced_dataset:\n",
    "        clf_output = clf_output[:5000]\n",
    "\n",
    "    if shuffled_dataset:\n",
    "        np.random.seed(42)\n",
    "        clf_output = clf_output.sample(frac=1)\n",
    "\n",
    "    docs_ids += list(clf_output.index)\n",
    "\n",
    "    D_b = len(clf_output)\n",
    "    source_size.append(D_b)\n",
    "    print(D_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976\n",
      "27665\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Шаг 1 -- получение случайного списка документов для доливания\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "docs_ids = list(map(lambda r: r[\"_id\"], db[\"postnauka\"].find({}, {\"_id\": 1})))\n",
    "source_size = []\n",
    "\n",
    "D_a = len(docs_ids)\n",
    "print(D_a)\n",
    "source_size.append(D_a)\n",
    "\n",
    "for csv_name, n_docs in ((\"classifier_output_habr.csv\", 27665),\n",
    "                         (\"classifier_output_elem.csv\", 0)):\n",
    "    clf_output = pd.read_csv(csv_name)\n",
    "    clf_output.columns = [\"id\", \"proba\"]\n",
    "    clf_output = clf_output.set_index(\"id\")[\"proba\"]\n",
    "\n",
    "    clf_output = clf_output.sample(n_docs)\n",
    "\n",
    "    docs_ids += list(clf_output.index)\n",
    "\n",
    "    D_b = len(clf_output)\n",
    "    source_size.append(D_b)\n",
    "    print(D_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**В `docs_ids` лежит ранжированный список документов, который потом разбивается на батчи (`batches`)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pn_2',\n",
       " 'pn_3',\n",
       " 'pn_4',\n",
       " 'pn_5',\n",
       " 'pn_6',\n",
       " 'pn_7',\n",
       " 'pn_8',\n",
       " 'pn_9',\n",
       " 'pn_13',\n",
       " 'pn_14']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_ids[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Дальше разбиваем на батчи. Можно по закону сложного процента:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Шаг 2а -- разбиение списка на батчи для итеративного доливания\n",
    "\n",
    "D_a0 = D_a // 3\n",
    "\n",
    "# Будем пользоваться законом сложного процента: размер i-ого батча будет считаться как размер (i-1)-ого батча + p%.\n",
    "# Тогда количество итераций n, необходимых для вливания коллекции размера D_b в коллекцию размера D_a, удовлетворяет:\n",
    "# D_a * (1 + p)^n = D_a + D_b\n",
    "# n = ln((D_a + D_b) / D_a) / ln(1 + p)\n",
    "\n",
    "p = 0.1\n",
    "batches = [docs_ids[:D_a], docs_ids[D_a:D_a + D_a0]]\n",
    "batch_pos = D_a + D_a0\n",
    "\n",
    "while batch_pos < len(docs_ids):\n",
    "    new_batch_size = int((1 + p) * len(batches[-1]))\n",
    "    batch = docs_ids[batch_pos:batch_pos + new_batch_size]\n",
    "    batches.append(batch)\n",
    "    batch_pos += new_batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**А можно просто слить всё в один батч:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Шаг 2б -- склеивание всей коллекции в один батч\n",
    "\n",
    "batches = [docs_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**А можно порезать все батчи, начиная со второго, на куски по 1000 штук:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = [docs_ids[:D_a], docs_ids[D_a:D_a + 1000], docs_ids[D_a + 1000:D_a + 2000],\n",
    "           docs_ids[D_a + 2000:D_a + 3000], docs_ids[D_a + 3000:D_a + 4000], docs_ids[D_a + 4000:D_a + 5000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**А можно сначала Постнауку, а потом -- всё остальное:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = [docs_ids[:D_a], docs_ids[D_a:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "batches = [docs_ids[:source_size[0]], docs_ids[source_size[0]:sum(source_size[:2])], docs_ids[sum(source_size[:2]):sum(source_size[:3])]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**А может быть, можно ещё как-то -- тут надо думать.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Размеры батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[30641]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(len, batches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Количество и суммарная длина батчей:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 30641)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batches), sum(map(len, batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Шаг 3 -- подгрузка словаря совстречаемостей (PPMI), подсчитываемого отдельного\n",
    "\n",
    "artm_cooc_path = \"merged_cooc_df_gt20.txt\"\n",
    "\n",
    "word_count = []\n",
    "row, col, data = [], [], []\n",
    "with open(artm_cooc_path) as cooc_f:\n",
    "    for line in cooc_f:\n",
    "        tokens = list(map(int, line.split()))\n",
    "        if len(tokens) == 1:\n",
    "            word_count.append(tokens[0])\n",
    "        elif len(tokens) == 3:\n",
    "            u, v, n_uv = tokens\n",
    "            p_uv = n_uv / word_count[v]\n",
    "            p_vu = n_uv / word_count[u]\n",
    "            row.append(u); col.append(v); data.append(p_uv)\n",
    "            row.append(v); col.append(u); data.append(p_vu)\n",
    "\n",
    "w = h = len(word_count)\n",
    "cooc_matrix = scipy.sparse.csr_matrix((data, (row, col)), shape=(w, h), dtype=np.float32)\n",
    "\n",
    "del row, col, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Параметры ARTM модели\n",
    "\n",
    "# Общий random seed\n",
    "artm_seed = 37\n",
    "\n",
    "# Названия тем\n",
    "# TODO: скрытые константы\n",
    "norm_topic_names = [\"topic_%d\" % i for i in range(0, 20)]\n",
    "background_names = [\"background_%d\" % i for i in range(0, 1)]\n",
    "topic_names0 = norm_topic_names + background_names\n",
    "\n",
    "# Регуляризаторы \n",
    "# Задаются ниже в цикле!\n",
    "regularizers_list0 = []\n",
    "regularizers_list0.append(artm.DecorrelatorPhiRegularizer(name=\"DecorrPhiReg\",\n",
    "                                                          topic_names=norm_topic_names,\n",
    "                                                          tau=500000))\n",
    "regularizers_list0.append(artm.SmoothSparseThetaRegularizer(name=\"SPPhiTagRegBackground\",\n",
    "                                                           topic_names=background_names,\n",
    "                                                           tau=10))\n",
    "\n",
    "# Веса всех модальностей\n",
    "class_ids0 = {\"text\": 1.0, \"flat_tag\": 300.0}\n",
    "class_ids1 = {\"text\": 1.0, \"flat_tag\": 25.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Параметры алгоритма CollectionMerge\n",
    "\n",
    "modalities_to_use = [\"flat_tag\", \"text\"]\n",
    "vw_path = \"batch_vw.txt\"\n",
    "artm_ppmi_path = \"merged_ppmi.txt\"\n",
    "artm_vocab_path = \"merged_vocab.txt\"\n",
    "artm_batch_path = \"merged_batches/\"\n",
    "tmp_artm_batch_path = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def build_level1(topics_cnt, level0, prev_phi, dictionary, batch_vectorizer, scores_list, use_regularizer=True, C=None):\n",
    "    # Названия тем\n",
    "    background_names = [\"background_%d\" % i for i in range(0, 1)]\n",
    "    norm_topic_names = [\"topic_%d\" % i for i in range(topics_cnt)]\n",
    "    topic_names1 = norm_topic_names + background_names\n",
    "\n",
    "    # Список регуляризаторов\n",
    "    regularizers_list1 = []\n",
    "#     regularizers_list1.append(artm.DecorrelatorPhiRegularizer(name=\"DecorrPhiReg1\",\n",
    "#                               topic_names=norm_topic_names, \n",
    "#                                 tau=500000 * sum(map(len, batches[:iter_no]))/len(batches[0])))\n",
    "#     regularizers_list1.append(artm.SmoothSparseThetaRegularizer(name=\"SPPhiTagRegBackground\",\n",
    "#                                                            topic_names=background_names,\n",
    "#                                                            tau=10))\n",
    "\n",
    "    # Создадим ARTM модель (второй уровень)\n",
    "    level1 = hierarchy_utils.ARTM_Level(level0, phi_batch_weight=10.0**3, \n",
    "                                        topic_names=topic_names1,\n",
    "                                        class_ids=class_ids1,\n",
    "                                        regularizers=regularizers_list1,\n",
    "                                        scores=scores_list,\n",
    "                                        num_document_passes=1,\n",
    "                                        cache_theta=True, theta_columns_naming=\"title\",\n",
    "                                        seed=artm_seed)\n",
    "    level1.initialize(dictionary=dictionary)\n",
    "\n",
    "    # Инициализиуем матрицу Фи значениями с предыдущей итерации\n",
    "    if prev_phi is not None:\n",
    "        _, phi_ref = level1.master.attach_model(level1.model_pwt)\n",
    "        print(prev_phi.shape, phi_ref.shape)\n",
    "        for i, j in itertools.product(*map(range, prev_phi.shape)):\n",
    "            phi_ref[i, j] = prev_phi[i, j]\n",
    "\n",
    "    # Улучшаем иерархическую когерентность с помощью регуляризатора\n",
    "    if use_regularizer and C is not None:\n",
    "        X = level0.get_phi().values.T * C\n",
    "        X[X < 1e-9] = 0\n",
    "        X = csr_matrix(X)\n",
    "        hc_tau = 1e6\n",
    "\n",
    "    # Обучим модель второго уровня\n",
    "    # TODO: подобрать количество итераций\n",
    "    for nit in range(5):\n",
    "        level1.fit_offline(batch_vectorizer, num_collection_passes=1)\n",
    "\n",
    "        # Улучшаем иерархическую когерентность с помощью регуляризатора\n",
    "        if use_regularizer and C is not None:\n",
    "            (_, pwt_ref) = level1.master.attach_model(model=level1.model_pwt)\n",
    "            (_, nwt_ref) = level1.master.attach_model(model=level1.model_nwt)\n",
    "\n",
    "            phi_delta = hc_tau * X.T.dot(1 / X.dot(pwt_ref))\n",
    "\n",
    "            phi_new = nwt_ref + np.multiply(pwt_ref, phi_delta)\n",
    "            phi_new[phi_new < 0] = 0\n",
    "            for mod_indices in merged_mod_map.values():\n",
    "                phi_new[mod_indices] /= phi_new[mod_indices].sum(axis=0)\n",
    "\n",
    "            np.copyto(pwt_ref, phi_new)\n",
    "\n",
    "    # Итеративное разреживание детей тем 0 уровня\n",
    "    threshold = 0.05\n",
    "    psi1 = level1.get_psi()\n",
    "    for tau in np.arange(0.1, 0.6, 0.1):\n",
    "        child_topics = []\n",
    "        for t in range(len(level0.topic_names)):\n",
    "            child_topics.append([])\n",
    "            for s, topic_name1 in enumerate(level1.topic_names):\n",
    "                if psi1.values[s, t] > threshold:\n",
    "                    child_topics[t].append(topic_name1)\n",
    "        # Разреживание детей каждой темы 0 уровня между собой\n",
    "        for i in range(len(level0.topic_names)):\n",
    "            topics_list = child_topics[i]\n",
    "#             level1.regularizers.add(artm.SmoothSparsePhiRegularizer(\n",
    "#                                     name=\"SPThetaReg_%d\" % i,\n",
    "#                                     topic_names=topics_list, \n",
    "#                                     tau=-tau * len(topics_list) ** 3), overwrite=True)\n",
    "        # Дообучим модель второго уровня\n",
    "        # TODO: подобрать количество итераций\n",
    "        level1.fit_offline(batch_vectorizer, num_collection_passes=1)\n",
    "\n",
    "        if use_regularizer and C is not None:\n",
    "            (_, pwt_ref) = level1.master.attach_model(model=level1.model_pwt)\n",
    "            (_, nwt_ref) = level1.master.attach_model(model=level1.model_nwt)\n",
    "\n",
    "            phi_delta = hc_tau * X.T.dot(1 / X.dot(pwt_ref))\n",
    "\n",
    "            phi_new = nwt_ref + np.multiply(pwt_ref, phi_delta)\n",
    "            phi_new[phi_new < 0] = 0\n",
    "            for mod_indices in merged_mod_map.values():\n",
    "                phi_new[mod_indices] /= phi_new[mod_indices].sum(axis=0)\n",
    "\n",
    "            np.copyto(pwt_ref, phi_new)\n",
    "\n",
    "    return level1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Собственно, алгоритм итеративного обучения CollectionMerge:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New vocab size: 44995\n",
      "Level 0 perplexity: 3631.160826\n",
      "Iteration 0, level 0 built\n",
      "Level 1 perplexity: 979.865317\n",
      "Iteration 0, level 1 built\n",
      "CPU times: user 9min 26s, sys: 32.9 s, total: 9min 59s\n",
      "Wall time: 9min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "max_batch_size = max(map(len, batches))\n",
    "\n",
    "vocab_map = {}\n",
    "prev_phi0 = None\n",
    "prev_phi1 = None\n",
    "\n",
    "docs_length = 0\n",
    "word_count = {}\n",
    "pair_count = {}\n",
    "\n",
    "all_chars = list(map(chr, range(ord('a'), ord('z') + 1)))\n",
    "artm_batch_names_iter = itertools.product(*([all_chars] * 6))\n",
    "batch_names = [\"\".join(next(artm_batch_names_iter)) for i in range(len(batches))]\n",
    "\n",
    "t2 = 60\n",
    "\n",
    "psis = []\n",
    "levels = []\n",
    "hiers = []\n",
    "\n",
    "# Удалим содержимое директории с ARTM батчами\n",
    "for fname in glob.glob(artm_batch_path + \"/*\"):\n",
    "    os.remove(fname)\n",
    "\n",
    "# Создадим файлы с ARTM vocabulary\n",
    "open(artm_vocab_path, \"w\").close()\n",
    "\n",
    "for iter_no, (batch_name, batch) in enumerate(zip(batch_names, batches)):\n",
    "    prev_vocab_size = len(vocab_map)\n",
    "    batch_vocab = []\n",
    "    batch_n_d = collections.defaultdict(int)\n",
    "    batch_n_wd = collections.defaultdict(int)\n",
    "\n",
    "    # Запишем документы и словарь из батча в файлы\n",
    "    with open(vw_path, \"w\") as vw_f, open(artm_vocab_path, \"a\") as vocab_f:\n",
    "        for i_d, doc in enumerate(map(get_document, batch)):\n",
    "            doc_id = doc[\"_id\"]\n",
    "            modalities_str = []\n",
    "            for mod_name in modalities_to_use:\n",
    "                mod = doc[\"modalities\"].get(mod_name, [])\n",
    "                mods = []\n",
    "                for token in mod:\n",
    "                    token = token.replace(\" \", \"_\")\n",
    "                    vocab_entry = (token, mod_name)\n",
    "                    if doc_id.startswith(\"pn_\"): # TODO: for comparability. Remove later.\n",
    "                        if iter_no == 0 or (iter_no > 0 and vocab_entry in vocab_map):\n",
    "                            mods.append(token)\n",
    "                        if iter_no == 0 and vocab_entry not in vocab_map:\n",
    "                            vocab_map[vocab_entry] = len(vocab_map)\n",
    "                            batch_vocab.append(vocab_entry)\n",
    "                    #i_w = vocab_map[vocab_entry]\n",
    "                    #batch_n_wd[i_w, i_d] += 1\n",
    "                modalities_str.append(\"|%s %s\" % (mod_name, \" \".join(mods)))\n",
    "                #for token in set(mod):\n",
    "                #    token = token.replace(\" \", \"_\")\n",
    "                #    i_w = vocab_map[token, mod_name]\n",
    "                #    batch_n_d[i_w] += 1\n",
    "            vw_f.write(\"%s %s\\n\" % (doc_id, \" \".join(modalities_str)))\n",
    "        for vocab_entry in batch_vocab:\n",
    "            vocab_f.write(\"%s %s\\n\" % vocab_entry)\n",
    "    \n",
    "    print(\"New vocab size:\", len(batch_vocab))\n",
    "    \n",
    "    # Создадим матрицу P(w_old|d_new)\n",
    "    \"\"\"\n",
    "    row, col, data = [], [], []\n",
    "    for (i_w, i_d), n_wd in batch_n_wd.items():\n",
    "        if i_w < prev_vocab_size:\n",
    "            p_wd = n_wd / batch_n_d[i_w]\n",
    "            row.append(i_w)\n",
    "            col.append(i_d)\n",
    "            data.append(p_wd)\n",
    "    w = prev_vocab_size\n",
    "    h = len(batch)\n",
    "    batch_p_wd_old = scipy.sparse.csr_matrix((data, (row, col)), shape=(w, h), dtype=np.float32)\n",
    "    \n",
    "    # Создадим матрицу P(w_new|d_new)\n",
    "    row, col, data = [], [], []\n",
    "    for (i_w, i_d), n_wd in batch_n_wd.items():\n",
    "        if i_w >= prev_vocab_size:\n",
    "            p_wd = n_wd / batch_n_d[i_w]\n",
    "            row.append(i_w - prev_vocab_size)\n",
    "            col.append(i_d)\n",
    "            data.append(p_wd)\n",
    "    w = len(batch_vocab)\n",
    "    h = len(batch)\n",
    "    batch_p_wd_new = scipy.sparse.csr_matrix((data, (row, col)), shape=(w, h), dtype=np.float32)\n",
    "    \"\"\"\n",
    "\n",
    "    # Создадим ARTM батч по нашему батчу\n",
    "    tmp_batch_vectorizer = artm.BatchVectorizer(data_format=\"vowpal_wabbit\", data_path=vw_path,\n",
    "                                                batch_size=max_batch_size, target_folder=tmp_artm_batch_path,\n",
    "                                                gather_dictionary=False)\n",
    "    # Хак: переименуем ARTM батч во временное имя,\n",
    "    # чтобы не мешать созданию других ARTM батчей\n",
    "    os.rename(\"%s/aaaaaa.batch\" % tmp_artm_batch_path,\n",
    "              \"%s/%s.batch\"     % (artm_batch_path, batch_name))\n",
    "\n",
    "    # Создадим ARTM модель (первый уровень)\n",
    "    dictionary = artm.Dictionary(\"dictionary\")\n",
    "    dictionary.gather(artm_batch_path, vocab_file_path=artm_vocab_path,\n",
    "                      cooc_file_path=artm_ppmi_path, symmetric_cooc_values=True)\n",
    "\n",
    "    # Метрики качества\n",
    "    scores_list = []\n",
    "    scores_list.append(artm.PerplexityScore(name=\"PerplexityScore\", class_ids=[\"text\"]))\n",
    "    scores_list.append(artm.TopTokensScore(name=\"Top50Tokens\", class_id=\"text\", num_tokens=50,\n",
    "                                           dictionary=dictionary))\n",
    "    scores_list.append(artm.TopTokensScore(name=\"Top10Tags\", class_id=\"flat_tag\", num_tokens=10,\n",
    "                                           dictionary=dictionary))\n",
    "    \n",
    "    regularizers_list0 = []\n",
    "    regularizers_list0.append(artm.DecorrelatorPhiRegularizer(name=\"DecorrPhiReg\",\n",
    "                                topic_names=norm_topic_names, \n",
    "                                tau=500000 * sum(map(len, batches[:iter_no]))/len(batches[0])))\n",
    "    regularizers_list0.append(artm.SmoothSparseThetaRegularizer(name=\"SPPhiTagRegBackground\",\n",
    "                                                           topic_names=background_names,\n",
    "                                                           tau=10))\n",
    "\n",
    "    level0 = artm.ARTM(topic_names=topic_names0, class_ids=class_ids0,\n",
    "                       regularizers=regularizers_list0, scores=scores_list,\n",
    "                       cache_theta=True, theta_columns_naming=\"title\",\n",
    "                       seed=artm_seed)\n",
    "    level0.initialize(dictionary=dictionary)\n",
    "\n",
    "    # Загрузим созданные на данный момент ARTM батчи\n",
    "    #data_paths = list(map(lambda i: \"%s/%d\" % (artm_batch_path, i), range(iter_no + 1)))\n",
    "    #data_weights = list((1 - p) ** np.arange(iter_no + 1))\n",
    "    batch_vectorizer = artm.BatchVectorizer(data_format=\"batches\", data_path=artm_batch_path,\n",
    "                                            gather_dictionary=False)\n",
    "\n",
    "    _, phi_ref = level0.master.attach_model(level0.model_pwt)\n",
    "    # Инициализиуем матрицу Фи значениями с предыдущей итерации\n",
    "    if prev_phi0 is not None:\n",
    "        # Инициализируем верхнюю часть Фи матрицей Фи с предыдущей итерации\n",
    "        print(prev_phi0.shape, phi_ref.shape)\n",
    "        for i, j in itertools.product(*map(range, prev_phi0.shape)):\n",
    "            phi_ref[i, j] = prev_phi0[i, j]\n",
    "\n",
    "        # Инициализируем нижнюю часть Фи различными оценками\n",
    "        ff_score = 0.0\n",
    "        if False:\n",
    "            start_token_id = prev_phi0.shape[0]\n",
    "            end_token_id = phi_ref.shape[0]\n",
    "\n",
    "            for token_id in range(start_token_id, end_token_id):\n",
    "                token_cooc_row = cooc_matrix[token_id]\n",
    "                data, col = token_cooc_row.data, token_cooc_row.nonzero()[1]\n",
    "\n",
    "                if len(data) > 0:\n",
    "                    length = np.argmin(col < start_token_id)\n",
    "\n",
    "                    pvt = prev_phi0[col[:length]]\n",
    "                    pwv = data[:length]\n",
    "                    pwt = pwv.dot(pvt)\n",
    "\n",
    "                    # Посчитаем метрику качества инициализции\n",
    "                    pvd_new = batch_p_wd_new[token_id - start_token_id]\n",
    "                    pvd_old = batch_p_wd_old[col[:length]]\n",
    "                    cf_score = pvd_new.toarray() - pvd_old.T.dot(pwv)\n",
    "                    ff_score += np.linalg.norm(cf_score)\n",
    "\n",
    "                    for j in range(prev_phi0.shape[1]):\n",
    "                        phi_ref[token_id, j] = pwt[j]\n",
    "                else:\n",
    "                    pvd_new = batch_p_wd_new[token_id - start_token_id]\n",
    "                    cf_score = pvd_new.toarray()\n",
    "                    ff_score += np.linalg.norm(cf_score)\n",
    "        #print(\"Level 0 FF score: %.6f\" % ff_score)\n",
    "    else:\n",
    "        with open(\"phi_level0.dump\", \"rb\") as fin:\n",
    "            pt_indices, pwt_new = pickle.load(fin)\n",
    "            phi_ref[pt_indices, :] = pwt_new\n",
    "\n",
    "    # Обучим модель первого уровня\n",
    "    # TODO: подобрать количество итераций\n",
    "    level0.fit_offline(batch_vectorizer, num_collection_passes=5)\n",
    "    print(\"Level 0 perplexity: %.6f\" % level0.score_tracker[\"PerplexityScore\"].last_value)\n",
    "    #print(\"Level 0 coherence: %.6f\" % level0.score_tracker[\"Top50Tokens\"].last_average_coherence)\n",
    "    print(\"Iteration %d, level 0 built\" % iter_no)\n",
    "\n",
    "    # Построим модель второго уровня\n",
    "    #max_coherence = 0\n",
    "    #max_t2 = cur_t2\n",
    "    #for t2 in range(cur_t2 - 4, cur_t2 + 12, 2):\n",
    "    level1 = build_level1(t2, level0, prev_phi1, dictionary, batch_vectorizer, scores_list, C=C)\n",
    "    print(\"Level 1 perplexity: %.6f\" % level1.score_tracker[\"PerplexityScore\"].last_value)\n",
    "    #print(\"Level 1 coherence: %.6f\" % level1.score_tracker[\"Top50Tokens\"].last_average_coherence)\n",
    "    print(\"Iteration %d, level 1 built\" % iter_no)\n",
    "    #if t2 == 19 * 3:\n",
    "    #    t2 += 10\n",
    "\n",
    "    # Сохраним матрицы Фи первого и второго уровня с текущей итерации\n",
    "    prev_phi0 = level0.get_phi().values\n",
    "    prev_phi1 = level1.get_phi().values\n",
    "\n",
    "    # Сохраним уровни для истории\n",
    "    #levels.append((level0, level1))\n",
    "    \n",
    "    # Сохраним иерархию\n",
    "    hier = hierarchy_utils.hARTM(class_ids=class_ids0, regularizers=regularizers_list0,\n",
    "                                 scores=scores_list, cache_theta=True, seed=artm_seed)\n",
    "\n",
    "    hier._levels.append(level0)\n",
    "    hier._levels.append(level1)\n",
    "    hiers.append(hier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "with reg:\n",
    "```\n",
    "Level 0 perplexity: 3631.160826\n",
    "Iteration 0, level 0 built\n",
    "Level 1 perplexity: 979.865317\n",
    "Iteration 0, level 1 built\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "without reg:\n",
    "```\n",
    "New vocab size: 44995\n",
    "Level 0 perplexity: 3631.160826\n",
    "Iteration 0, level 0 built\n",
    "Level 1 perplexity: 841.582459\n",
    "Iteration 0, level 1 built\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.22 s, sys: 129 ms, total: 5.35 s\n",
      "Wall time: 5.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "model_name = \"../article/baseline_random_pnv_wreg.new\"\n",
    "os.makedirs(model_name, exist_ok=True)\n",
    "\n",
    "with open(\"%s/phi_0_text\" % model_name, \"wb\") as fout:\n",
    "    pickle.dump(hiers[-1][0].get_phi(class_ids=\"text\"), fout)\n",
    "\n",
    "with open(\"%s/phi_1_text\" % model_name, \"wb\") as fout:\n",
    "    pickle.dump(hiers[-1][1].get_phi(class_ids=\"text\"), fout)\n",
    "    \n",
    "with open(\"%s/psi\" % model_name, \"wb\") as fout:\n",
    "    pickle.dump(hiers[-1][1].get_psi(), fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "hiers[-1].save(\"hartm\")\n",
    "\n",
    "extra_info = {\n",
    "    \"class_ids\": class_ids0,\n",
    "    \"theta\": hiers[-1].get_theta(),\n",
    "    \"spectrums\": []\n",
    "}\n",
    "\n",
    "pickle.dump(extra_info, open(\"hartm/extra_info.dump\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Получившиеся темы первого уровня:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('background_0', 'белки антропология мозг'),\n",
       " ('topic_0', 'математика суперкомпьютеры компьютерное_моделирование'),\n",
       " ('topic_1', 'технологии информационные_технологии интернет'),\n",
       " ('topic_10', 'история история_россии средневековье'),\n",
       " ('topic_11', 'политика политология государство'),\n",
       " ('topic_12', 'социология общество город'),\n",
       " ('topic_13', 'культура литература культурология'),\n",
       " ('topic_14', 'образование наука университет'),\n",
       " ('topic_15', 'язык лингвистика филология'),\n",
       " ('topic_16', 'философия история_философии политическая_философия'),\n",
       " ('topic_17', 'христианство религия востоковедение'),\n",
       " ('topic_18', 'россия сша география'),\n",
       " ('topic_19', 'право юриспруденция римское_право'),\n",
       " ('topic_2', 'физика физика_элементарных_частиц квантовая_физика'),\n",
       " ('topic_3', 'химия материаловедение молекула'),\n",
       " ('topic_4', 'земля солнечная_система солнце'),\n",
       " ('topic_5', 'астрономия астрофизика вселенная'),\n",
       " ('topic_6', 'биология эволюция геном'),\n",
       " ('topic_7', 'медицина генетика биомедицина'),\n",
       " ('topic_8', 'психология мозг нейробиология'),\n",
       " ('topic_9', 'экономика сша общество')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k, \" \".join(v[:3])) for k, v in hiers[-1]._levels[0].score_tracker[\"Top10Tags\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('background_0',\n",
       "  'город мозг пространство часть раса форма представлять структура общество группа'),\n",
       " ('topic_0',\n",
       "  'число задача математика математический решение простой пространство модель точка результат'),\n",
       " ('topic_1',\n",
       "  'технология данные сеть информация компьютер задача использовать работать робот создавать'),\n",
       " ('topic_10',\n",
       "  'война исторический историк власть революция русский государство политический король часть'),\n",
       " ('topic_11',\n",
       "  'политический государство власть политика страна война партия общество право сталин'),\n",
       " ('topic_12',\n",
       "  'социальный социология пространство город общество отношение объект событие сообщество действие'),\n",
       " ('topic_13',\n",
       "  'культура фильм культурный советский искусство литература русский кино текст смысл'),\n",
       " ('topic_14',\n",
       "  'университет образование научный ученый школа студент знание хороший результат академический'),\n",
       " ('topic_15',\n",
       "  'русский словарь речь текст ребенок языковой значение глагол лингвист часть'),\n",
       " ('topic_16',\n",
       "  'философия философ философский понятие политический идея смысл знание культура классический'),\n",
       " ('topic_17',\n",
       "  'бог христианский традиция имя культура христианство восток церковь остров цивилизация'),\n",
       " ('topic_18',\n",
       "  'россия российский страна русский политический развитие государственный европа отношение население'),\n",
       " ('topic_19',\n",
       "  'право закон правовой римский суд юрист сага отношение юридический судья'),\n",
       " ('topic_2',\n",
       "  'частица квантовый поле энергия физика кварк электрон взаимодействие атом свет'),\n",
       " ('topic_3',\n",
       "  'материал молекула структура химия химический метод вещество соединение элемент атом'),\n",
       " ('topic_4',\n",
       "  'планета земля атмосфера вода солнце солнечный поверхность газ марс температура'),\n",
       " ('topic_5',\n",
       "  'звезда галактика вселенная дыра черный объект масса излучение вещество энергия'),\n",
       " ('topic_6',\n",
       "  'клетка ген вид организм животное днк эволюция белок группа растение'),\n",
       " ('topic_7',\n",
       "  'клетка заболевание болезнь пациент препарат лечение организм метод ген врач'),\n",
       " ('topic_8',\n",
       "  'мозг ребенок память нейрон задача решение психология внимание поведение информация'),\n",
       " ('topic_9',\n",
       "  'экономический страна экономика рынок компания цена решение рост банк китай')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k, \" \".join(v[:10])) for k, v in hiers[-1]._levels[0].score_tracker[\"Top50Tokens\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Получившиеся темы второго уровня:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('background_0', 'россия экономика философия'),\n",
       " ('topic_1', 'нейробиология когнитивная_психология человек'),\n",
       " ('topic_10', 'онкология стволовые_клетки антибиотики'),\n",
       " ('topic_11', 'физика физика_элементарных_частиц квантовая_физика'),\n",
       " ('topic_13', 'астрономия химия вселенная'),\n",
       " ('topic_15', 'фольклор фольклористика русская_литература'),\n",
       " ('topic_17', 'массовая_культура культурология фольклор'),\n",
       " ('topic_19', 'биология генетика ген'),\n",
       " ('topic_21', 'востоковедение религиозные_войны католицизм'),\n",
       " ('topic_22', 'биология птицы флуоресцентные_белки'),\n",
       " ('topic_24', 'востоковедение кавказ религиоведение'),\n",
       " ('topic_25', 'гмо белки биотехнологии'),\n",
       " ('topic_32', 'физика фарадей_майкл античастица'),\n",
       " ('topic_33', 'технологии информационные_технологии искусственный_интеллект'),\n",
       " ('topic_38', 'история история_россии первая_мировая_война'),\n",
       " ('topic_39', 'язык лингвистика филология'),\n",
       " ('topic_42', 'земля солнечная_система экзопланета'),\n",
       " ('topic_43', 'наука история_науки академическая_среда'),\n",
       " ('topic_45',\n",
       "  'теория_принятия_решений финансовый_рынок экономическое_развитие'),\n",
       " ('topic_46', 'сталин_иосиф либерализм политическая_философия'),\n",
       " ('topic_53', 'банковская_система финансовый_кризис средний_класс'),\n",
       " ('topic_57', 'суперкомпьютеры компьютерное_моделирование топология'),\n",
       " ('topic_59', 'русский_язык лингвистика корпусная_лингвистика'),\n",
       " ('topic_6', 'история_права гуманитарные_науки юриспруденция'),\n",
       " ('topic_7', 'социология идентичность социология_повседневности'),\n",
       " ('topic_9', 'микросоциология социология урбанистика')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k, \" \".join(v[:3])) for k, v in hiers[-1]._levels[1].score_tracker[\"Top10Tags\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('background_0', 'земля'),\n",
       " ('topic_1', 'мозг психология нейрон мышление память'),\n",
       " ('topic_10', 'медицина'),\n",
       " ('topic_11', 'кварк электрон симметрия оптика лазер'),\n",
       " ('topic_13', 'астрофизика космос галактика материаловедение гравитация'),\n",
       " ('topic_15', 'культура литература театр искусство ориенталистика'),\n",
       " ('topic_17', 'культура философия литература кино искусство'),\n",
       " ('topic_19', 'медицина эволюция днк клетка право'),\n",
       " ('topic_21', 'религия африка христианство китай майя'),\n",
       " ('topic_22', 'днк этология эволюция геномика клетка'),\n",
       " ('topic_24', 'христианство религия китай археология ислам'),\n",
       " ('topic_25', 'этология эволюция селекция днк'),\n",
       " ('topic_32', 'фотоника кварк электрон коллайдер частица'),\n",
       " ('topic_33', 'интернет информатика робот электроника энергия'),\n",
       " ('topic_38', 'россия средневековье европа германия русь'),\n",
       " ('topic_39', 'грамматика речь диалект фонетика языкознание'),\n",
       " ('topic_42', 'планета солнце геология география экология'),\n",
       " ('topic_43', 'образование университет школа егэ диссертация'),\n",
       " ('topic_45', 'экономика сша общество государство рынок'),\n",
       " ('topic_46', 'политика политология государство ссср демократия'),\n",
       " ('topic_53', 'экономика инфляция дефляция рынок промышленность'),\n",
       " ('topic_57', 'математика геометрия алгебра кибернетика логика'),\n",
       " ('topic_59', 'речь словарь грамматика коммуникация фонетика'),\n",
       " ('topic_6', 'право рим судопроизводство исландия государство'),\n",
       " ('topic_7', 'общество город фрейм москва эпистемология'),\n",
       " ('topic_9', 'глобализация общество национализм город определяться')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(k, \" \".join(v[:5])) for k, v in hiers[-1]._levels[1].score_tracker[\"Top50Tokens\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#for level_id, level in enumerate(levels):\n",
    "#    level.save(\"article_models/new_random_small_batches_%d.model\" % level_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Какие-то статистики (в том числе и из старой Машиной тетрадки), которые можно позапускать без гарантии успеха:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Proposed algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "phi0 = levels[0].get_phi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.mean((phi0 > 0).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.median((phi0 > 0).sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sorted([(k, \" \".join(v[:3])) for k, v in levels[0].score_tracker[\"Top50Tokens\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "sorted([(k, \" \".join(v[:3])) for k, v in levels[-1].score_tracker[\"Top10Tags\"].last_tokens.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fdpsi1 = level1.get_psi()\n",
    "\n",
    "tokens0 = hiers[-1]._levels[0].score_tracker[\"Top50Tokens\"].last_tokens\n",
    "tokens1 = hiers[-1]._levels[1].score_tracker[\"Top50Tokens\"].last_tokens\n",
    "threshold = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m PARENT:  topic_0: объект значение число алгоритм точка функция метод задача данные результат  \u001b[0m\n",
      "    topic_57: математика статистика объект значение логика геометрия число алгоритм кибернетика точка \n",
      "\u001b[1;31m PARENT:  topic_1: пользователь данные использовать приложение сеть информация сервер возможность данный программа  \u001b[0m\n",
      "    topic_33: дизайн интернет электроника пользователь информатика криптография сеть использовать сервер интерфейс \n",
      "    topic_35: приложение данные программист информация компьютер разработчик файл разработка управление помощь \n",
      "    topic_48: робот микроэлектроника ресурс режим часть версия ключ данный различный пример \n",
      "    background_0: интернет пользователь данные сервис веб программа возможность решение реализация приложение \n",
      "\u001b[1;31m PARENT:  topic_2: частица квантовый поле волна энергия физика свет скорость электрон атом  \u001b[0m\n",
      "    topic_2: кварк лазер симметрия gps сверхпроводимость коллайдер адрон оптика суперсимметрия электрон \n",
      "    topic_5: поле состояние взаимодействие разъем модель движение информация эксперимент момент скорость \n",
      "    topic_11: датчик частота транзистор корпус линия выход преобразование передача емкость фильтр \n",
      "    topic_29: компьютер приемник конфигурация точка масса сохранение ноль выключать мышка равный \n",
      "    topic_32: свет электрон оптика частица протон коллайдер квантовый кварк gps материя \n",
      "    topic_54: скорость бит поле механика сила эксперимент свет элементарный поток cms \n",
      "\u001b[1;31m PARENT:  topic_3: устройство напряжение сигнал датчик питание камера материал ток плата схема  \u001b[0m\n",
      "    topic_11: датчик частота транзистор корпус линия выход преобразование передача емкость фильтр \n",
      "    topic_23: схема камера использовать слой управление использоваться производитель провод конструкция модуль \n",
      "    topic_44: материаловедение энергия энергетика кристалл устройство углерод микроскопия водород биохимия кристаллография \n",
      "\u001b[1;31m PARENT:  topic_4: земля космический планета полет двигатель корабль аппарат марс ракета спутник  \u001b[0m\n",
      "    topic_42: космос марс экология планета луна география геология климат атмосфера венера \n",
      "\u001b[1;31m PARENT:  topic_5: звезда вселенная галактика черный энергия дыра телескоп материя масса излучение  \u001b[0m\n",
      "    topic_8: масса пространство горячий пк видеть момент примерно увидеть мало масштаб \n",
      "    topic_13: астрофизика гравитация космос телескоп энергия звезда галактика материя свет излучение \n",
      "    topic_27: красный метрика доработка релиз смещение сжатие количество колонка обнаруживать шаг \n",
      "    topic_40: мощность наблюдать яркость персонал кадр двигаться союз отображаться авария сфера \n",
      "    topic_47: астрофизика галактика гравитация солнце космос радиоастрономия телескоп звезда астероид гравитационный \n",
      "    topic_52: солнце космос телескоп галактика звезда объект черный гравитация планета астрофизика \n",
      "\u001b[1;31m PARENT:  topic_6: клетка ген днк организм вид животное белок эволюция растение молекула  \u001b[0m\n",
      "    topic_14: патент вид форма условие жить возникать результат метод высокий злоумышленник \n",
      "    topic_19: эволюция биоинформатика палеонтология зоология клетка днк рнк альтруизм растение моногамия \n",
      "    topic_22: днк эволюция этология геномика рнк палеонтология клетка зоология полигамия миозин \n",
      "    topic_25: эволюция клетка адаптация ученый структура развитие вид последовательность отбор эволюционный \n",
      "    topic_28: медитация указанный буфер иной билет розетка отключать мотор крепление связывать \n",
      "    topic_30: вид часть дрожжи место находиться давать колесо тысяча задний вставлять \n",
      "    topic_34: команда питание грипп вакцина группа контроль снижать индикатор аппарат профиль \n",
      "    topic_51: клетка днк мутация белок биоинформатика рнк метаболизм организм эмбриология кислород \n",
      "\u001b[1;31m PARENT:  topic_7: клетка болезнь пациент заболевание врач лечение препарат медицинский организм боль  \u001b[0m\n",
      "    topic_10: медицина биомедицина вирус иммунитет рак биофизика хирургия фармакология смерть неврология \n",
      "    topic_34: команда питание грипп вакцина группа контроль снижать индикатор аппарат профиль \n",
      "\u001b[1;31m PARENT:  topic_8: мозг нейрон память информация ребенок задача интеллект эмоция сознание активность  \u001b[0m\n",
      "    topic_1: мозг психология нейрон память мотивация мышление сознание интеллект сон нейропсихология \n",
      "    topic_45: зрение внимание информация задача действие активность поведение уровень результат область \n",
      "\u001b[1;31m PARENT:  topic_9: компания клиент бизнес деньги рынок продукт цена товар продажа реклама  \u001b[0m\n",
      "    topic_53: экономика сша реклама компания рынок клиент бизнес япония деньги продукт \n",
      "\u001b[1;31m PARENT:  topic_10: война исторический германия историк революция король власть немецкий русский политический  \u001b[0m\n",
      "    topic_0: средневековье германия франция англия историография русь власть медиевистика инквизиция папство \n",
      "    topic_38: европа банк империя израиль германия маршрут русский республика немецкий власть \n",
      "    topic_49: стартапа власть уведомление монитор часть плата великий конец исторический виза \n",
      "\u001b[1;31m PARENT:  topic_11: политический государство страна власть политика общество партия женщина война правительство  \u001b[0m\n",
      "    topic_4: политика государство ссср политология власть демократия нация национализм великобритания война \n",
      "    topic_36: философия античность аристотель платон этика марксизм мораль сократ капитализм личность \n",
      "    topic_46: документ коммунизм регистрация правительство социализм ребенок сми группа подписывать безопасность \n",
      "\u001b[1;31m PARENT:  topic_12: социальный город пространство общество сообщество отношение социология событие объект вещь  \u001b[0m\n",
      "    topic_7: общество медиа утопия фрейм город эпистемология оружие антиутопия этикет маргинальность \n",
      "    topic_9: социальный скрипт класс вещь взаимодействие медиа отношение оружие форма группа \n",
      "    topic_31: автомобиль рекламный маркетинг контент офис телефон водитель событие помещение отношение \n",
      "    topic_37: город сообщество медиа общество оружие лондон оператор лицензия бразилия пространство \n",
      "\u001b[1;31m PARENT:  topic_13: фильм персонаж культура сцена игра автор герой искусство музыка кино  \u001b[0m\n",
      "    topic_3: культура кино литература искусство мифология кинематограф театр миф авангард поэзия \n",
      "    topic_15: литература культура миф фильм библиотека автор игра сказка кадр искусство \n",
      "\u001b[1;31m PARENT:  topic_14: проект задача команда заказчик разработка работать программист решение сотрудник разработчик  \u001b[0m\n",
      "    topic_12: образование университет школа задача проект аспирантура детство диссертация решение код \n",
      "    topic_43: проект образование заказчик разработчик менеджер разработка компания сотрудник специалист этап \n",
      "\u001b[1;31m PARENT:  topic_15: текст русский буква речь английский словарь символ шрифт перевод клавиатура  \u001b[0m\n",
      "    topic_6: имя текст заметка умолчание регистр фраза письмо ибо бумажный исправление \n",
      "    topic_39: игровой экран текст звук звонок клавиатура шрифт клавиша компьютер абонент \n",
      "    topic_41: речь текст русский буква поэзия ия яндекс знак дискурс значение \n",
      "    topic_50: речь символ бот предложение ребенок английский рунет заводить категория писать \n",
      "    topic_58: программирование куча папка часть перевод обещать мобильный опция название вася \n",
      "    topic_59: грамматика диалект словарь семантика фонетика языкознание праязык лексика психолингвистика синтаксис \n",
      "\u001b[1;31m PARENT:  topic_16: философия идея понятие свобода философский мысль философ человеческий знание смысл  \u001b[0m\n",
      "    topic_17: личность информационный классика греция идея произведение письмо конверсия смысл знание \n",
      "    topic_36: философия античность аристотель платон этика марксизм мораль сократ капитализм личность \n",
      "\u001b[1;31m PARENT:  topic_17: китай китайский бог древний церковь христианский восток цивилизация традиция имя  \u001b[0m\n",
      "    topic_21: китай колонизация цивилизация календарь италия китайский ритуал возрождение медитация магия \n",
      "    topic_24: христианство религия китай археология ислам майя письменность африка русь мезоамерика \n",
      "    topic_49: стартапа власть уведомление монитор часть плата великий конец исторический виза \n",
      "\u001b[1;31m PARENT:  topic_18: россия карта страна город российский интернет банк номер автомобиль москва  \u001b[0m\n",
      "    topic_38: европа банк империя израиль германия маршрут русский республика немецкий власть \n",
      "    topic_55: россия украина москва европа сколково транспорт глобализация терроризм карта страна \n",
      "\u001b[1;31m PARENT:  topic_19: право информация документ закон договор лицо защита электронный информационный данные  \u001b[0m\n",
      "    topic_56: право закон суд коммуникация рим информация полиция договор лицо судопроизводство \n",
      "\u001b[1;31m PARENT:  background_0: игра работать хороший хотеть давать место статья находить нужный решать  \u001b[0m\n",
      "    topic_16: архитектура музыка игра этнография находить писать написать второй испания читать \n",
      "    topic_18: работать физиология час решать хотеть кнопка пара неделя выбирать команда \n",
      "    topic_20: игрок рука давать работать блог телефон хотеть хороший нужный возможность \n",
      "    topic_26: статья хороший часть момент место австралия ничто простой нужный игра \n",
      "\n",
      " edges:  66\n",
      "61 topics have parents\n"
     ]
    }
   ],
   "source": [
    "child_topics = []\n",
    "output = ''\n",
    "related = 0\n",
    "for t, topic_name in enumerate(level0.topic_names):\n",
    "    child_topics.append([])\n",
    "    output += topic_name + ': '\n",
    "    for word in tokens0[topic_name][:10]:    \n",
    "        output += word + ' '\n",
    "    print(\"\\x1b[1;31m PARENT: \", output, '\\x1b[0m')\n",
    "    output=''\n",
    "    for s, topic_name1 in enumerate(level1.topic_names):\n",
    "        if (psi1.values[s, t] > threshold):\n",
    "            child_topics[t].append(topic_name1)\n",
    "            related += 1\n",
    "            output += \"    \"+ topic_name1 + ': '\n",
    "            for word in tokens1[topic_name1][:10]:    \n",
    "                output += word + ' '\n",
    "            print (output)\n",
    "            output =''\n",
    "print(\"\\n edges: \", related)\n",
    "\n",
    "related_topics = 0\n",
    "for row in (psi1.values>threshold):\n",
    "    if (sum(row) != 0):\n",
    "        related_topics += 1\n",
    "\n",
    "print(related_topics,\"topics have parents\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m PARENT:  topic_0: история_россии философия история политическая_философия история_философии античность археология русь платон аристотель  \u001b[0m\n",
      "    topic_0: философия античность археология русь аристотель платон архитектура украина россия этика \n",
      "    topic_21: философия религия смерть русский политический имя эпоха древний бог свобода \n",
      "    topic_27: философия университет марксизм феминизм идеология водород закон ученый капитализм дворянство \n",
      "\u001b[1;31m PARENT:  topic_1: эволюция антропология биология человек палеонтология геология антропогенез физиология происхождение_человека расоведение  \u001b[0m\n",
      "    topic_14: эволюция палеонтология физиология геология иммунология этнография неврология этнос раса homo \n",
      "    topic_20: вид группа развитие общий часть давать связь возникать показывать результат \n",
      "    topic_45: геология эволюция сон признак изменение древний жить период группа форма \n",
      "\u001b[1;31m PARENT:  topic_2: экономика география информационная_безопасность авторское_право финансовый_кризис финансовый_рынок экономическое_неравенство экономическое_развитие новая_институциональная_экономика коррупция  \u001b[0m\n",
      "    topic_2: экономика география компания рынок деньги проект бизнес клиент капитал промышленность \n",
      "\u001b[1;31m PARENT:  topic_3: культура литература массовая_культура культурология филология кино искусство литературоведение кинематограф театр  \u001b[0m\n",
      "    topic_3: культура литература искусство кинематограф театр кино ритуал авангард поэзия франция \n",
      "    topic_17: культура литература кино кинематограф музыка искусство поэзия театр ритуал авангард \n",
      "    topic_28: автор интересный показывать хороший конец выходить прочитывать представлять давать читать \n",
      "    topic_36: текст смысл писать написать русский пример интересный вещь сторона форма \n",
      "\u001b[1;31m PARENT:  topic_4: история политика ссср христианство религия германия власть востоковедение европа история_россии  \u001b[0m\n",
      "    topic_8: считать идея исторический сила конец великий сторона писать начало собственный \n",
      "    topic_21: философия религия смерть русский политический имя эпоха древний бог свобода \n",
      "    topic_24: политика германия религия ссср христианство власть франция европа ислам война \n",
      "    topic_46: страна советский европа революция отношение второй создавать выступать начало принимать \n",
      "    topic_48: политика европа цивилизация война политический национализм великобритания власть конституция партия \n",
      "    topic_49: христианство ссср политика религия власть историография германия ислам демократия франция \n",
      "\u001b[1;31m PARENT:  topic_5: астрономия астрофизика вселенная космос звезды галактика земля черные_дыры солнечная_система солнце  \u001b[0m\n",
      "    topic_13: результат составлять размер вещество поскольку открытие достаточно расширение основной небольшой \n",
      "    topic_47: астрофизика космос галактика планета солнце марс гравитация луна телескоп атмосфера \n",
      "    topic_57: астрофизика космос галактика солнце телескоп атмосфера гравитация планета звезда масса \n",
      "    background_0: энергия центр мало размер крупный масса данные проект оставаться количество \n",
      "\u001b[1;31m PARENT:  topic_6: язык лингвистика филология право русский_язык юриспруденция урбанистика грамматика римское_право речь  \u001b[0m\n",
      "    topic_6: право грамматика словарь фонетика лексика москва диалект диалектология морфология судопроизводство \n",
      "    topic_36: текст смысл писать написать русский пример интересный вещь сторона форма \n",
      "    topic_39: форма вид правило часть второй психолингвистика право тип предложение текст \n",
      "    topic_50: речь москва право рим лексика коммуникация грамматика фонетика психолингвистика русский \n",
      "    topic_58: право речь грамматика языкознание диалект праязык синтаксис словарь коммуникация фонетика \n",
      "\u001b[1;31m PARENT:  topic_7: социология город общество социология_повседневности городское_пространство дюркгейм_эмиль вебер_макс социология_пространства гоффман_эрвинг теория_фреймов  \u001b[0m\n",
      "    topic_7: город общество сообщество демография мода фрейм утопия класс оружие элита \n",
      "    topic_9: социальный общество отношение пространство класс объект представлять тип правило пример \n",
      "    topic_31: событие игра город объект отношение социальный общество пространство ситуация сообщество \n",
      "\u001b[1;31m PARENT:  topic_8: россия общество государство сша политология европа идентичность китай политика нация  \u001b[0m\n",
      "    topic_7: город общество сообщество демография мода фрейм утопия класс оружие элита \n",
      "    topic_30: россия сша общество государство политология китай япония европа глобализация нация \n",
      "    topic_38: россия общество государство политология европа сша англия китай нация политика \n",
      "    topic_48: политика европа цивилизация война политический национализм великобритания власть конституция партия \n",
      "\u001b[1;31m PARENT:  topic_9: психология интернет когнитивная_психология мышление социальные_сети интеллект сверхпроводимость стресс память внимание  \u001b[0m\n",
      "    topic_42: мышление внимание память ресурс информация задача решение зрение сеть интеллект \n",
      "    topic_56: психология интернет интеллект стресс сверхпроводимость мышление мотивация внимание психика кибернетика \n",
      "\u001b[1;31m PARENT:  topic_10: медицина биология генетика днк ген геном клетка онкология биомедицина белки  \u001b[0m\n",
      "    topic_1: медицина днк клетка рнк биохимия болезнь мутация биомедицина хирургия вирус \n",
      "    topic_4: клетка вирус биофизика вызывать работать многий уровень метод давать результат \n",
      "    topic_10: медицина биомедицина клетка биохимия днк мутация рак фармакология биофизика хирургия \n",
      "    topic_51: вирус организм биологический биофизика животное ученый белок вид метод форма \n",
      "    topic_59: клетка развитие медицина уровень помощь результат приводить метод орган ученый \n",
      "\u001b[1;31m PARENT:  topic_11: физика физика_элементарных_частиц квантовая_физика кварк элементарная_частица стандартная_модель большой_адронный_коллайдер бозон_хиггса магнитное_поле квантовая_механика  \u001b[0m\n",
      "    topic_5: движение поле свет описывать состояние сила помощь известный момент возникать \n",
      "    topic_11: свет гравитация электроника протон электрон лазер оптика поле адрон коллайдер \n",
      "    topic_15: результат момент создавать уровень представлять давать значение решать создание равный \n",
      "    topic_29: закон модель точка поле результат пространство направление область состоять представлять \n",
      "    topic_32: протон электроника энергия свет электрон частица коллайдер эксперимент кварк взаимодействие \n",
      "    topic_35: кварк симметрия электрон оптика лазер суперсимметрия коллайдер электроника спин криптография \n",
      "    topic_54: описывать сила общий возникать результат второй высокий давать оставаться пример \n",
      "\u001b[1;31m PARENT:  topic_12: философия наука история_науки университет гендер кант_иммануил академическая_среда марксизм социология_науки маркс_карл  \u001b[0m\n",
      "    topic_12: университет энергетика философия марксизм личность суд феминизм закон научный магия \n",
      "    topic_27: философия университет марксизм феминизм идеология водород закон ученый капитализм дворянство \n",
      "    topic_37: статья работать проект задача решение знание качество область практика создавать \n",
      "    topic_41: научный философия личность автор статья деятельность университет знание идея интерес \n",
      "\u001b[1;31m PARENT:  topic_13: химия нанотехнологии космология материаловедение темная_материя реликтовое_излучение кристалл наноматериалы космическая_инфляция кристаллография  \u001b[0m\n",
      "    topic_13: результат составлять размер вещество поскольку открытие достаточно расширение основной небольшой \n",
      "    topic_23: структура элемент метод связь реакция вещество область технология электронный свойство \n",
      "    topic_44: материаловедение кристалл кристаллография углерод микроскопия катализ спектроскопия микроэлектроника фтор катализатор \n",
      "    topic_53: материал высокий свойство метод температура элемент число простой вещество использовать \n",
      "\u001b[1;31m PARENT:  topic_14: образование школа общество медиа майя детство мораль мезоамерика немецкая_классическая_философия палеоботаника  \u001b[0m\n",
      "    topic_40: образование школа медиа общество майя детство мораль мезоамерика чтение мексика \n",
      "\u001b[1;31m PARENT:  topic_15: технологии математика информационные_технологии информатика робототехника computer_science робот машинное_обучение геометрия топология  \u001b[0m\n",
      "    topic_25: математика информатика робот геометрия алгебра задача код частица статистика gps \n",
      "    topic_33: данные статистика программа разработка компьютер программист математика информация функция использовать \n",
      "    topic_52: решение программа управление использовать проект подход возможность часть задача создание \n",
      "\u001b[1;31m PARENT:  topic_16: средневековье молекулярная_биология мифология биоинформатика фольклор фольклористика миф геномика секвенирование католицизм  \u001b[0m\n",
      "    topic_16: средневековье мифология биоинформатика миф геномика дизайн испания папство обряд колонизация \n",
      "    topic_55: сторона заниматься давать место видеть представление род конец начинаться определенный \n",
      "\u001b[1;31m PARENT:  topic_17: биология экология зоология этология поведение_животных африка нобелевская_премия зоопсихология вирусология логика  \u001b[0m\n",
      "    topic_18: экология зоология этология африка логика библиотека агрессия мышление животное самец \n",
      "    topic_51: вирус организм биологический биофизика животное ученый белок вид метод форма \n",
      "\u001b[1;31m PARENT:  topic_18: мозг искусственный_интеллект нейробиология нейрон нейрофизиология нейронные_сети сознание память нейропсихология принятие_решений  \u001b[0m\n",
      "    topic_42: мышление внимание память ресурс информация задача решение зрение сеть интеллект \n",
      "    topic_43: мозг нейрон сознание память нейропсихология климат сон нейронаука справедливость эпистемология \n",
      "\u001b[1;31m PARENT:  background_0: биология микробиология биотехнологии бактерии микробы клетка иммунитет биофизика антибиотики вирус  \u001b[0m\n",
      "    topic_4: клетка вирус биофизика вызывать работать многий уровень метод давать результат \n",
      "    topic_19: работать технология вид часть нужный вариант топливо условие качество деталь \n",
      "    topic_22: место находиться небольшой часть количество использовать второй показывать позволять достаточно \n",
      "    topic_26: часто количество заниматься способ находить сложный тип позволять основной помогать \n",
      "    topic_34: иммунитет клетка биофизика белок кислород метаболизм нефть вирус климат питание \n",
      "    topic_51: вирус организм биологический биофизика животное ученый белок вид метод форма \n",
      "\n",
      " edges:  71\n",
      "61 topics have parents\n"
     ]
    }
   ],
   "source": [
    "child_topics = []\n",
    "output = ''\n",
    "related = 0\n",
    "for t, topic_name in enumerate(level0.topic_names):\n",
    "    child_topics.append([])\n",
    "    output += topic_name + ': '\n",
    "    for word in tokens0[topic_name][:10]:    \n",
    "        output += word + ' '\n",
    "    print(\"\\x1b[1;31m PARENT: \", output, '\\x1b[0m')\n",
    "    output=''\n",
    "    for s, topic_name1 in enumerate(level1.topic_names):\n",
    "        if (psi1.values[s, t] > threshold):\n",
    "            child_topics[t].append(topic_name1)\n",
    "            related += 1\n",
    "            output += \"    \"+ topic_name1 + ': '\n",
    "            for word in tokens1[topic_name1][:10]:    \n",
    "                output += word + ' '\n",
    "            print (output)\n",
    "            output =''\n",
    "print(\"\\n edges: \", related)\n",
    "\n",
    "related_topics = 0\n",
    "for row in (psi1.values>threshold):\n",
    "    if (sum(row) != 0):\n",
    "        related_topics += 1\n",
    "\n",
    "print(related_topics,\"topics have parents\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Модель Постнауки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4014.377057868622,\n",
       " 3997.412386903887,\n",
       " 3983.4014716661077,\n",
       " 3971.371280361148,\n",
       " 3961.1586255593693]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level0.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1658.0593815180423,\n",
       " 1690.214988651034,\n",
       " 1735.0400707548297,\n",
       " 1774.8115995426745,\n",
       " 1808.6524507405409]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level1.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Top10Tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-127b7c2ff45b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Top10Tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Top10Tokens'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level0.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Top10Tokens'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-27b83285928f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\": \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlevel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore_tracker\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Top10Tokens\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'Top10Tokens'"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level1.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level0.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level1.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Предлагаемый алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level0.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level1.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level0.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level1.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level0.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level1.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "docs_lengths = {}\n",
    "\n",
    "for doc in map(get_document, docs_ids):\n",
    "    docs_lengths[doc[\"_id\"]] = len(doc[\"modalities\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta0 = level0.get_theta()\n",
    "\n",
    "docs_lengths_series = pd.Series(docs_lengths)\n",
    "pn_docs_ids = list(filter(lambda doc_id: doc_id.startswith(\"pn_\"), docs_ids))\n",
    "n_pn_topics = theta0[pn_docs_ids].dot(docs_lengths_series.loc[pn_docs_ids])\n",
    "n_topics = theta0.dot(docs_lengths_series)\n",
    "n_topics /= n_topics.sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(n_topics[:-1], n_pn_topics[:-1])\n",
    "plt.xlabel(\"$p(t)$\")\n",
    "plt.ylabel(\"$n_t^{ПН}$\")\n",
    "#plt.xlim([0, 0.02])\n",
    "#plt.ylim([0, 25000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta1 = level1.get_theta()\n",
    "\n",
    "docs_lengths_series = pd.Series(docs_lengths)\n",
    "pn_docs_ids = list(filter(lambda doc_id: doc_id.startswith(\"pn_\"), docs_ids))\n",
    "n_pn_topics = theta1[pn_docs_ids].dot(docs_lengths_series.loc[pn_docs_ids])\n",
    "n_topics = theta1.dot(docs_lengths_series)\n",
    "n_topics /= n_topics.sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(n_topics, n_pn_topics)\n",
    "plt.xlabel(\"$p(t)$\")\n",
    "plt.ylabel(\"$n_t^{ПН}$\")\n",
    "#plt.xlim([0, 0.02])\n",
    "#plt.ylim([0, 25000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Базовый алгоритм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level0.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level1.score_tracker[\"PerplexityScore\"].value[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level0.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\"\\n\".join([k + \": \" + \" \".join(v) for k, v in level1.score_tracker[\"Top10Tokens\"].last_tokens.items()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level0.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "level1.score_tracker[\"Top10Tokens\"].last_average_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "docs_lengths = {}\n",
    "\n",
    "for doc in map(get_document, docs_ids):\n",
    "    docs_lengths[doc[\"_id\"]] = len(doc[\"modalities\"][\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta0 = level0.get_theta()\n",
    "\n",
    "docs_lengths_series = pd.Series(docs_lengths)\n",
    "pn_docs_ids = list(filter(lambda doc_id: doc_id.startswith(\"pn_\"), docs_ids))\n",
    "n_pn_topics = theta0[pn_docs_ids].dot(docs_lengths_series.loc[pn_docs_ids])\n",
    "n_topics = theta0.dot(docs_lengths_series)\n",
    "n_topics /= n_topics.sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(n_topics[:-1], n_pn_topics[:-1])\n",
    "plt.xlabel(\"$p(t)$\")\n",
    "plt.ylabel(\"$n_t^{ПН}$\")\n",
    "#plt.xlim([0, 0.02])\n",
    "#plt.ylim([0, 25000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "theta1 = level1.get_theta()\n",
    "\n",
    "docs_lengths_series = pd.Series(docs_lengths)\n",
    "pn_docs_ids = list(filter(lambda doc_id: doc_id.startswith(\"pn_\"), docs_ids))\n",
    "n_pn_topics = theta1[pn_docs_ids].dot(docs_lengths_series.loc[pn_docs_ids])\n",
    "n_topics = theta1.dot(docs_lengths_series)\n",
    "n_topics /= n_topics.sum()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(n_topics, n_pn_topics)\n",
    "plt.xlabel(\"$p(t)$\")\n",
    "plt.ylabel(\"$n_t^{ПН}$\")\n",
    "#plt.xlim([0, 0.02])\n",
    "#plt.ylim([0, 25000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**NB**: в конце провести эксперимент на перемешанном clf_output -- гипотеза о независимости качества от порядка вливания документов в ТМ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
