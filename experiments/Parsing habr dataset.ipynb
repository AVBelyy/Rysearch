{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Хабрахабр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import regex\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from pymongo import MongoClient\n",
    "from sklearn.pipeline import Pipeline\n",
    "from parsers.text_utils import DefaultTextProcessor, DefaultDocumentProcessor\n",
    "from ipywidgets import FloatProgress\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Перегоняем данные из базы `test.habrahabr` в базу `datasets.habrahabr` с изменением формата и сохраняем на диске в формате Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "in_collection = client[\"test\"][\"habrahabr\"]\n",
    "out_collection = client[\"datasets\"][\"habrahabr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "stop_words = open(\"../datasets/habrahabr/stopwords.txt\").read().split()\n",
    "rare_words = open(\"../datasets/habrahabr/rarewords.txt\").read().split()\n",
    "stop_lemmas = set(stop_words).union(set(rare_words))\n",
    "doc_pipeline = Pipeline([\n",
    "    (\"text-processor\",     DefaultTextProcessor(token_pattern=\"(?u)\\\\b\\\\p{L}+\\\\b\")),\n",
    "    (\"document-processor\", DefaultDocumentProcessor(stop_lemmas=stop_lemmas)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 26 ms, total: 1.66 s\n",
      "Wall time: 1.67 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: вынести разнесение токенов по двум модальностям (MOD и MOD_habr) в отдельный модуль\n",
    "\n",
    "pn_vocab = {\"text\": set(), \"flat_tag\": set()}\n",
    "\n",
    "for doc in open(\"../datasets/postnauka/postnauka.txt\"):\n",
    "    tokens = doc.split()\n",
    "    for token in tokens[1:]:\n",
    "        if token.startswith(\"|\"):\n",
    "            cur_mod = token[1:]\n",
    "        else:\n",
    "            if cur_mod == \"text\" or cur_mod == \"flat_tag\":\n",
    "                pn_vocab[cur_mod].add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44995"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pn_vocab[\"text\"]) + len(pn_vocab[\"flat_tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_tag(tag):\n",
    "    return \"_\".join(regex.findall(\"(?u)\\\\b\\\\p{L}+\\\\b\", tag.strip().lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 31s, sys: 35 s, total: 17min 6s\n",
      "Wall time: 1h 8min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "docs_count = in_collection.count({ \"company_blog\": None })\n",
    "f = FloatProgress(min=0, max=docs_count)\n",
    "display(f)\n",
    "\n",
    "with open(\"../datasets/habrahabr/habrahabr.txt\", \"w\") as vw_file:\n",
    "    for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "        doc = {}\n",
    "        doc[\"_id\"] = \"habr_%d\" % doc_id\n",
    "        doc[\"title\"] = mongo_doc[\"title\"]\n",
    "        doc[\"url\"] = mongo_doc[\"url\"]\n",
    "        doc[\"modalities\"] = {\"text_habr\": [], \"text\": [], \"flat_tag_habr\": [], \"flat_tag\": []}\n",
    "        modalities = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "        for token in modalities[\"text\"]:\n",
    "            if token in pn_vocab[\"text\"]:\n",
    "                doc[\"modalities\"][\"text\"].append(token)\n",
    "            else:\n",
    "                doc[\"modalities\"][\"text_habr\"].append(token)\n",
    "        for token in map(preprocess_tag, mongo_doc[\"tags\"]):\n",
    "            if token in pn_vocab[\"flat_tag\"]:\n",
    "                doc[\"modalities\"][\"flat_tag\"].append(token)\n",
    "            else:\n",
    "                doc[\"modalities\"][\"flat_tag_habr\"].append(token)\n",
    "        doc[\"modalities\"][\"authors\"] = [mongo_doc[\"author_user\"]]\n",
    "        doc[\"modalities\"][\"hubs\"] = mongo_doc[\"hubs\"]\n",
    "        doc[\"markdown\"] = mongo_doc[\"content_html\"]\n",
    "        # TODO: подтягивать имена авторов с Хабра\n",
    "        doc[\"authors_names\"] = doc[\"modalities\"][\"authors\"]\n",
    "        # Фильтрация коротких документов из Хабра\n",
    "        if len(doc[\"modalities\"][\"text\"]) + len(doc[\"modalities\"][\"text_habr\"]) > 100:\n",
    "            # Записать в Vowpal Wabbit\n",
    "            modalities_str = \" \".join(map(lambda p: \"|%s %s\" % (p[0],\n",
    "                             \" \".join(map(lambda t: \"_\".join(t.split()), p[1]))), doc[\"modalities\"].items()))\n",
    "            vw_file.write(\"%s %s\\n\" % (doc[\"_id\"], modalities_str))\n",
    "            # Записать в MongoDB\n",
    "            out_collection.insert_one(doc)\n",
    "        # Увеличить счетчик прогресс-бара\n",
    "        f.value += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Фильтрация слов с низким DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 18min 34s, sys: 29.3 s, total: 19min 3s\n",
      "Wall time: 1h 7min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "docs_count = in_collection.count({ \"company_blog\": None })\n",
    "f = FloatProgress(min=0, max=docs_count)\n",
    "display(f)\n",
    "\n",
    "word_counter = defaultdict(set)\n",
    "\n",
    "for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "    modalities = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "    for word in modalities[\"text\"]:\n",
    "        word_counter[word].add(doc_id)\n",
    "    # Увеличить счетчик прогресс-бара\n",
    "    f.value += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "words = list(word_counter.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "602833"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rare_words = set(map(lambda p: p[0], filter(lambda p: len(p[1]) <= 1, words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384972\n",
      "0.6386047213739129\n"
     ]
    }
   ],
   "source": [
    "print(len(rare_words))\n",
    "print(len(rare_words) / len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4415124"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"../datasets/habrahabr/rarewords.txt\", \"w\").write(\"\\n\".join(rare_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
