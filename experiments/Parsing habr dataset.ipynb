{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хабрахабр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pymongo import MongoClient\n",
    "from sklearn.pipeline import Pipeline\n",
    "from parsers.text_utils import DefaultTextProcessor, DefaultDocumentProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перегоняем данные из базы `test.habrahabr` в базу `datasets.habrahabr` с изменением формата и сохраняем на диске в формате Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "in_collection = client[\"test\"][\"habrahabr\"]\n",
    "out_collection = client[\"datasets\"][\"habrahabr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = open(\"../datasets/habrahabr/stopwords.txt\").read().split()\n",
    "top_5_percent_words = open(\"../datasets/habrahabr/top5_percent_words.txt\").read().split()\n",
    "stop_lemmas = list(set(stop_words).union(set(top_5_percent_words)))\n",
    "doc_pipeline = Pipeline([\n",
    "    (\"text-processor\",     DefaultTextProcessor(token_pattern=\"(?u)\\\\b\\\\p{L}+\\\\b\")),\n",
    "    (\"document-processor\", DefaultDocumentProcessor(stop_lemmas=stop_lemmas)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество встречающихся слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 35s, sys: 5.54 s, total: 8min 41s\n",
      "Wall time: 44min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "with open(\"../datasets/habrahabr/habrahabr.txt\", \"w\") as vw_file:\n",
    "    for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "        modalities = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "        word_counter.update(modalities[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результат в БД и на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top5_percent_words = list(map(lambda p: p[0], word_counter.most_common(int(len(word_counter) * 0.05))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "266801"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"../datasets/habrahabr/top5_percent_words.txt\", \"w\").write(\"\\n\".join(top5_percent_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 42s, sys: 12.2 s, total: 9min 54s\n",
      "Wall time: 48min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"../datasets/habrahabr/habrahabr.txt\", \"w\") as vw_file:\n",
    "    for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "        doc = {}\n",
    "        doc[\"_id\"] = \"habr_%d\" % doc_id\n",
    "        doc[\"title\"] = mongo_doc[\"title\"]\n",
    "        doc[\"url\"] = mongo_doc[\"url\"]\n",
    "        doc[\"modalities\"] = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "        doc[\"modalities\"][\"flat_tag\"] = mongo_doc[\"tags\"]\n",
    "        doc[\"modalities\"][\"authors\"] = [mongo_doc[\"author_user\"]]\n",
    "        doc[\"modalities\"][\"hubs\"] = mongo_doc[\"hubs\"]\n",
    "        doc[\"markdown\"] = mongo_doc[\"content_html\"]\n",
    "        # Записать в Vowpal Wabbit\n",
    "        modalities_str = \" \".join(map(lambda p: \"|%s %s\" % (p[0],\n",
    "                         \" \".join(map(lambda t: \"_\".join(t.split()), p[1]))), doc[\"modalities\"].items()))\n",
    "        vw_file.write(\"%s %s\\n\" % (doc[\"_id\"], modalities_str))\n",
    "        # Записать в MongoDB\n",
    "        out_collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
