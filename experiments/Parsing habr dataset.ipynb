{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Хабрахабр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from pymongo import MongoClient\n",
    "from sklearn.pipeline import Pipeline\n",
    "from parsers.text_utils import DefaultTextProcessor, DefaultDocumentProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перегоняем данные из базы `test.habrahabr` в базу `datasets.habrahabr` с изменением формата и сохраняем на диске в формате Vowpal Wabbit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient()\n",
    "in_collection = client[\"test\"][\"habrahabr\"]\n",
    "out_collection = client[\"datasets\"][\"habrahabr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = open(\"../datasets/habrahabr/stopwords.txt\").read().split()\n",
    "top_words = open(\"../datasets/habrahabr/topwords.txt\").read().split()\n",
    "stop_lemmas = list(set(stop_words).union(set(top_words)))\n",
    "doc_pipeline = Pipeline([\n",
    "    (\"text-processor\",     DefaultTextProcessor(token_pattern=\"(?u)\\\\b\\\\p{L}+\\\\b\")),\n",
    "    (\"document-processor\", DefaultDocumentProcessor(stop_lemmas=stop_lemmas)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем количество встречающихся слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 33s, sys: 5.89 s, total: 8min 39s\n",
      "Wall time: 44min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "word_counter = Counter()\n",
    "\n",
    "with open(\"../datasets/habrahabr/habrahabr.txt\", \"w\") as vw_file:\n",
    "    for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "        modalities = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "        word_counter.update(modalities[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем результат в БД и на диск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_words = list(map(lambda p: p[0], word_counter.most_common(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(\"../datasets/habrahabr/top_words.txt\", \"w\").write(\"\\n\".join(top_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nix/store/dscz9yyvr3s32v2b82c2bqdnxpvpzfj4-python3.5-ipykernel-4.3.1/lib/python3.5/site-packages/ipykernel/__main__.py:4: DeprecationWarning: save is deprecated. Use insert_one or replace_one instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 29s, sys: 3.79 s, total: 1min 33s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Фикс, чтобы сделать имена авторов на Хабре\n",
    "\n",
    "for doc in out_collection.find():\n",
    "    doc[\"authors_names\"] = doc[\"modalities\"][\"authors\"]\n",
    "    out_collection.save(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.51 s, sys: 6 ms, total: 1.52 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: вынести разнесение токенов по двум модальностям (MOD и MOD_habr) в отдельный модуль\n",
    "\n",
    "pn_vocab = {\"text\": set(), \"flat_tag\": set()}\n",
    "\n",
    "for doc in open(\"../datasets/postnauka/postnauka.txt\"):\n",
    "    tokens = doc.split()\n",
    "    for token in tokens[1:]:\n",
    "        if token.startswith(\"|\"):\n",
    "            cur_mod = token[1:]\n",
    "        else:\n",
    "            if cur_mod == \"text\" or cur_mod == \"flat_tag\":\n",
    "                pn_vocab[cur_mod].add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45093"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pn_vocab[\"text\"]) + len(pn_vocab[\"flat_tag\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocess_tag(tag):\n",
    "    return \"_\".join(regex.findall(\"(?u)\\\\b\\\\p{L}+\\\\b\", tag.strip().lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 9s, sys: 15.2 s, total: 12min 24s\n",
      "Wall time: 1h 3min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with open(\"../datasets/habrahabr/habrahabr.txt\", \"w\") as vw_file:\n",
    "    for doc_id, mongo_doc in enumerate(in_collection.find({ \"company_blog\": None }), 1):\n",
    "        doc = {}\n",
    "        doc[\"_id\"] = \"habr_%d\" % doc_id\n",
    "        doc[\"title\"] = mongo_doc[\"title\"]\n",
    "        doc[\"url\"] = mongo_doc[\"url\"]\n",
    "        doc[\"modalities\"] = {\"text_habr\": [], \"text\": [], \"flat_tag_habr\": [], \"flat_tag\": []}\n",
    "        modalities = doc_pipeline.fit_transform(mongo_doc[\"content_html\"])\n",
    "        for token in modalities[\"text\"]:\n",
    "            if token in pn_vocab[\"text\"]:\n",
    "                doc[\"modalities\"][\"text\"].append(token)\n",
    "            else:\n",
    "                doc[\"modalities\"][\"text_habr\"].append(token)\n",
    "        for token in map(preprocess_tag, mongo_doc[\"tags\"]):\n",
    "            if token in pn_vocab[\"flat_tag\"]:\n",
    "                doc[\"modalities\"][\"flat_tag\"].append(token)\n",
    "            else:\n",
    "                doc[\"modalities\"][\"flat_tag_habr\"].append(token)\n",
    "        doc[\"modalities\"][\"authors\"] = [mongo_doc[\"author_user\"]]\n",
    "        doc[\"modalities\"][\"hubs\"] = mongo_doc[\"hubs\"]\n",
    "        doc[\"markdown\"] = mongo_doc[\"content_html\"]\n",
    "        # TODO: подтягивать имена авторов с Хабра\n",
    "        doc[\"authors_names\"] = doc[\"modalities\"][\"authors\"]\n",
    "        # Фильтрация коротких документов из Хабра\n",
    "        if len(doc[\"modalities\"][\"text\"]) + len(doc[\"modalities\"][\"text_habr\"]) > 100:\n",
    "            # Записать в Vowpal Wabbit\n",
    "            modalities_str = \" \".join(map(lambda p: \"|%s %s\" % (p[0],\n",
    "                             \" \".join(map(lambda t: \"_\".join(t.split()), p[1]))), doc[\"modalities\"].items()))\n",
    "            vw_file.write(\"%s %s\\n\" % (doc[\"_id\"], modalities_str))\n",
    "            # Записать в MongoDB\n",
    "            out_collection.insert_one(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
